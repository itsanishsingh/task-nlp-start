{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49447eb-3744-49b0-b0dc-696d05c55a1a",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "NLP is a sub-field of AI and is created from fields like linguistics, computer science and AI. Here the task is for the machines to understand natural language and help them in solving a problem or better assist them through it in speech format. For example, helping people in ATM booths to better guide them through the interface. There are some tasks of NLP which are as follows:-\n",
    "\n",
    "* Text Classification\n",
    "* Sentiment Analysis\n",
    "* Information Retrieval\n",
    "* Parts of Speech Tagging\n",
    "* Language Detection and Machine Translation\n",
    "* Conversational Agents\n",
    "* Knowledge Graph and QA System\n",
    "* Text Summarization\n",
    "* Topic Modelling\n",
    "* Text Generation\n",
    "* Text Parsing\n",
    "* Speech to Text\n",
    "\n",
    "There are some approaches to NLP which are as follows:-\n",
    "\n",
    "* Heuristic Method\n",
    "* Machine Learning Method\n",
    "* Deep Learning Method\n",
    "\n",
    "Challenges in NLP:-\n",
    "\n",
    "* Ambiguity\n",
    "* Contextual Words\n",
    "* Colloquialism and Slangs\n",
    "* Synonyms\n",
    "* Irony, Sarcasm and Tonal Difference\n",
    "* Spelling Errors\n",
    "* Creativity\n",
    "* Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dbd7a-7b57-4a2d-949f-e5b0c7b4bde7",
   "metadata": {},
   "source": [
    "# NLP Pipeline\n",
    "It is set of steps followed to build an end to end NLP software.These steps are:-\n",
    "\n",
    "* Data Acquisition\n",
    "* Text Preparation\n",
    "  * Text Cleanup\n",
    "  * Basic Preprocessing\n",
    "  * Advance Preprocessing\n",
    "* Feature Engineering\n",
    "* Modelling\n",
    "  * Building\n",
    "  * Evaluation\n",
    "* Deployment\n",
    "  * Deployment\n",
    "  * Monitoring\n",
    "  * Model Update\n",
    "\n",
    "Notes:-\n",
    "\n",
    "* This is not universal\n",
    "* DL pipelines are slightly different\n",
    "* Pipeline is non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2f8ee-ea99-4ed2-95a4-66396aac36b2",
   "metadata": {},
   "source": [
    "### Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcccc72d-cfc0-41b6-929d-54285a292872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from textblob import TextBlob # Took too long\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9bfb92-f352-4aba-89e9-69b2a3afa64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/anish/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/anish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c460e5-d796-4b16-b0ac-10d9ef162086",
   "metadata": {},
   "source": [
    "The above have to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61334f9-8eae-46b6-b78d-0a764378a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"imdb_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6014c487-d0b0-4d73-bc2e-17ceb06221dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fe41f-6e1b-4455-a7ac-19d060c7fc5a",
   "metadata": {},
   "source": [
    "First step would be to change the case to lower as python is a case-sensitive language and mismatch cases will result in different tokens even though they are same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30e58ff-3eb0-4ae0-a768-ab3e40a92ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a83f0c9-6e3b-4dfa-9baf-a9c0ec22448c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb8cee-4cc6-4e04-9a3f-f3d1c027167a",
   "metadata": {},
   "source": [
    "Now we use regular expression to remove html tags as they are of no use to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e39ff0-682e-4f3f-9cbb-9d81a9ab9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(data):\n",
    "    pattern = re.compile(\"<.*?>\")\n",
    "    return pattern.sub(r\"\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54a4e48-793f-48a1-bb46-93ebbb238370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167d280f-2465-4236-8d7e-accf270c2c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f960a-5364-4f79-b3b0-6339d7198ec6",
   "metadata": {},
   "source": [
    "Next step would be to remove urls from the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287e4e2a-178f-494b-b25a-ec6ad880d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(data):\n",
    "    pattern = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return pattern.sub(r\"\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42efc7ef-0873-4c49-96af-87fecb5e8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac2b308-2504-49be-b3a0-2ebdd7574bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b9986-4070-4b08-9faf-6fff3bfee474",
   "metadata": {},
   "source": [
    "Next step is to remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f475ba3-9379-4a84-b0e5-b84abd55e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9140085-8f89-4aa0-bdcb-3fdbdbe356be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(data):\n",
    "    for char in punctuations:\n",
    "        data = data.replace(char, \"\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0a0281-b566-4f6a-a4d6-cd7f0cad1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df\n",
    "df_temp.review = df_temp.review.apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "036021b8-35e6-41d2-bdef-9da57899665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569895e-8b93-44b6-b842-7b87b8c44b4a",
   "metadata": {},
   "source": [
    "The above method works but is slow so when we have a huge dataset it would be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "922a929f-ceac-4fdb-90c3-316e4fe045b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    return data.translate(str.maketrans(\"\", \"\", punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b50aa3d-9647-47bd-a536-dab75b31f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0dcf5ee-b0a1-49ca-9d16-399ef540d478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993a8f5-b59c-42dc-83c8-f4d9587794f4",
   "metadata": {},
   "source": [
    "Next step would be chat word treatment. This deals with shortforms that are used instead of their actual self. We would need a dictionary where keys would be shortform and value will be their meaning. This is an important part for any application that interacts with real users as they generaly use these shortforms. But currently we will move to spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b70704-874e-4a4d-a41f-afc499116451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spell(data):\n",
    "    return spell(data)\n",
    "\n",
    "spell = Speller(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38e6f097-395a-4854-9885-715c7fdb3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.review = df.review.apply(correct_spell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb14116-a625-4edc-ab7d-fc9349a3260d",
   "metadata": {},
   "source": [
    "The above step takes too long with both textblob and autocorrect so lets skip them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07a13f67-8f26-4b26-82ab-bcf765858225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b887e111-5990-4f8a-8a3a-0c46f2ed2d23",
   "metadata": {},
   "source": [
    "Next step would be to get rid of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff7d789-2eb7-46ce-bdb6-80baa5448eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1939e76e-ed62-4299-b94e-f534ecca74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    end_string = []\n",
    "    for word in data.split():\n",
    "        if word not in en_stopwords:\n",
    "            end_string.append(word)\n",
    "    return \" \".join(end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "304b344f-3641-40d0-976f-20e447dbab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb46b11-9d3f-447a-89be-d34da42c7797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically theres family little boy jake thinks...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e496b66-226b-49bb-ad83-17d84f4102f4",
   "metadata": {},
   "source": [
    "The next step is tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231f08a2-c1b8-41e5-800a-bbf6694236ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a5f0227-ccfb-4475-a42d-caee8bf37bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'youll',\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'methe',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'hardcore',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'wordit',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'manyaryans',\n",
       " 'muslims',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christians',\n",
       " 'italians',\n",
       " 'irish',\n",
       " 'moreso',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'awayi',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'wouldnt',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romanceoz',\n",
       " 'doesnt',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'couldnt',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watched',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'wholl',\n",
       " 'sold',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " 'wholl',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewingthats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71cdf6d2-ba19-4b21-8278-4d2437394bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one reviewers mentioned watching 1 oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far awayi would say main appeal show due fact goes shows wouldnt dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards wholl sold nickel inmates wholl kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d6556-0be5-4ab7-ad2c-e8bdca83a130",
   "metadata": {},
   "source": [
    "The above are just examples from sample of data as all the data will take a long time. Spacy is another library which can help here. Next step is Stemming. It basically means to bring every word back to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc73f78-b2f8-45cf-b83d-5bec6230e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9d67324-60b4-43c6-9753-b95e8cb0994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(data):\n",
    "    return \" \".join([ps.stem(word) for word in data.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e7f4ee8-e993-4d21-a61e-3bec5d030de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review mention watch 1 oz episod youll hook right exactli happen meth first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use wordit call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home manyaryan muslim gangsta latino christian italian irish moreso scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show wouldnt dare forget pretti pictur paint mainstream audienc forget charm forget romanceoz doesnt mess around first episod ever saw struck nasti surreal couldnt say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard wholl sold nickel inmat wholl kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort viewingthat get touch darker side'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0a16d-aca3-4c38-8887-1671c03caaf4",
   "metadata": {},
   "source": [
    "As we can see every word has been reverted back to their root form but the root word may not be of the same language so we can also use Lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "292359b2-ba4c-4ccf-8f11-2a4691a56366",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1bffe5a-060e-48a8-977e-ab5c59fd8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = word_tokenize(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c51b6a29-1858-42a7-b40d-3830ac5dd218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one, one\n",
      "reviewers, reviewers\n",
      "mentioned, mention\n",
      "watching, watch\n",
      "1, 1\n",
      "oz, oz\n",
      "episode, episode\n",
      "youll, youll\n",
      "hooked, hook\n",
      "right, right\n",
      "exactly, exactly\n",
      "happened, happen\n",
      "methe, methe\n",
      "first, first\n",
      "thing, thing\n",
      "struck, strike\n",
      "oz, oz\n",
      "brutality, brutality\n",
      "unflinching, unflinching\n",
      "scenes, scenes\n",
      "violence, violence\n",
      "set, set\n",
      "right, right\n",
      "word, word\n",
      "go, go\n",
      "trust, trust\n",
      "show, show\n",
      "faint, faint\n",
      "hearted, hearted\n",
      "timid, timid\n",
      "show, show\n",
      "pulls, pull\n",
      "punches, punch\n",
      "regards, regard\n",
      "drugs, drug\n",
      "sex, sex\n",
      "violence, violence\n",
      "hardcore, hardcore\n",
      "classic, classic\n",
      "use, use\n",
      "wordit, wordit\n",
      "called, call\n",
      "oz, oz\n",
      "nickname, nickname\n",
      "given, give\n",
      "oswald, oswald\n",
      "maximum, maximum\n",
      "security, security\n",
      "state, state\n",
      "penitentary, penitentary\n",
      "focuses, focus\n",
      "mainly, mainly\n",
      "emerald, emerald\n",
      "city, city\n",
      "experimental, experimental\n",
      "section, section\n",
      "prison, prison\n",
      "cells, cells\n",
      "glass, glass\n",
      "fronts, front\n",
      "face, face\n",
      "inwards, inwards\n",
      "privacy, privacy\n",
      "high, high\n",
      "agenda, agenda\n",
      "em, em\n",
      "city, city\n",
      "home, home\n",
      "manyaryans, manyaryans\n",
      "muslims, muslims\n",
      "gangstas, gangstas\n",
      "latinos, latinos\n",
      "christians, christians\n",
      "italians, italians\n",
      "irish, irish\n",
      "moreso, moreso\n",
      "scuffles, scuffle\n",
      "death, death\n",
      "stares, star\n",
      "dodgy, dodgy\n",
      "dealings, dealings\n",
      "shady, shady\n",
      "agreements, agreements\n",
      "never, never\n",
      "far, far\n",
      "awayi, awayi\n",
      "would, would\n",
      "say, say\n",
      "main, main\n",
      "appeal, appeal\n",
      "show, show\n",
      "due, due\n",
      "fact, fact\n",
      "goes, go\n",
      "shows, show\n",
      "wouldnt, wouldnt\n",
      "dare, dare\n",
      "forget, forget\n",
      "pretty, pretty\n",
      "pictures, picture\n",
      "painted, paint\n",
      "mainstream, mainstream\n",
      "audiences, audiences\n",
      "forget, forget\n",
      "charm, charm\n",
      "forget, forget\n",
      "romanceoz, romanceoz\n",
      "doesnt, doesnt\n",
      "mess, mess\n",
      "around, around\n",
      "first, first\n",
      "episode, episode\n",
      "ever, ever\n",
      "saw, saw\n",
      "struck, strike\n",
      "nasty, nasty\n",
      "surreal, surreal\n",
      "couldnt, couldnt\n",
      "say, say\n",
      "ready, ready\n",
      "watched, watch\n",
      "developed, develop\n",
      "taste, taste\n",
      "oz, oz\n",
      "got, get\n",
      "accustomed, accustom\n",
      "high, high\n",
      "levels, level\n",
      "graphic, graphic\n",
      "violence, violence\n",
      "violence, violence\n",
      "injustice, injustice\n",
      "crooked, crook\n",
      "guards, guard\n",
      "wholl, wholl\n",
      "sold, sell\n",
      "nickel, nickel\n",
      "inmates, inmates\n",
      "wholl, wholl\n",
      "kill, kill\n",
      "order, order\n",
      "get, get\n",
      "away, away\n",
      "well, well\n",
      "mannered, mannered\n",
      "middle, middle\n",
      "class, class\n",
      "inmates, inmates\n",
      "turned, turn\n",
      "prison, prison\n",
      "bitches, bitch\n",
      "due, due\n",
      "lack, lack\n",
      "street, street\n",
      "skills, skills\n",
      "prison, prison\n",
      "experience, experience\n",
      "watching, watch\n",
      "oz, oz\n",
      "may, may\n",
      "become, become\n",
      "comfortable, comfortable\n",
      "uncomfortable, uncomfortable\n",
      "viewingthats, viewingthats\n",
      "get, get\n",
      "touch, touch\n",
      "darker, darker\n",
      "side, side\n"
     ]
    }
   ],
   "source": [
    "for word in word_token:\n",
    "    print(f\"{word}, {wordnet.lemmatize(word, pos=\"v\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ecbce-c57b-4444-9130-e619db66d958",
   "metadata": {},
   "source": [
    "Now our task is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c19bd8-8ef3-4ce6-9f4e-7d32aa9dcdb4",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c40f6ee-153e-473d-8cbd-886e501adf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da53f603-f827-4c8e-b7d4-26c5d5c2ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = cv.fit_transform(df.iloc[:2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2fbfed2-bc37-4bec-9347-88b2490d949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': 121, 'reviewers': 148, 'mentioned': 108, 'watching': 200, 'oz': 125, 'episode': 47, 'youll': 211, 'hooked': 86, 'right': 149, 'exactly': 50, 'happened': 81, 'methe': 110, 'first': 61, 'thing': 184, 'struck': 176, 'brutality': 11, 'unflinching': 194, 'scenes': 153, 'violence': 197, 'set': 161, 'word': 205, 'go': 71, 'trust': 190, 'show': 166, 'faint': 56, 'hearted': 83, 'timid': 186, 'pulls': 139, 'punches': 140, 'regards': 146, 'drugs': 40, 'sex': 163, 'hardcore': 82, 'classic': 19, 'use': 195, 'wordit': 206, 'called': 12, 'nickname': 119, 'given': 68, 'oswald': 124, 'maximum': 106, 'security': 157, 'state': 174, 'penitentary': 129, 'focuses': 63, 'mainly': 100, 'emerald': 44, 'city': 17, 'experimental': 52, 'section': 156, 'prison': 136, 'cells': 13, 'glass': 70, 'fronts': 65, 'face': 54, 'inwards': 89, 'privacy': 137, 'high': 84, 'agenda': 2, 'em': 43, 'home': 85, 'manyaryans': 103, 'muslims': 115, 'gangstas': 66, 'latinos': 95, 'christians': 16, 'italians': 91, 'irish': 90, 'moreso': 113, 'scuffles': 154, 'death': 30, 'stares': 173, 'dodgy': 36, 'dealings': 29, 'shady': 164, 'agreements': 3, 'never': 117, 'far': 58, 'awayi': 8, 'would': 208, 'say': 152, 'main': 99, 'appeal': 4, 'due': 41, 'fact': 55, 'goes': 72, 'shows': 167, 'wouldnt': 209, 'dare': 27, 'forget': 64, 'pretty': 135, 'pictures': 131, 'painted': 126, 'mainstream': 101, 'audiences': 6, 'charm': 14, 'romanceoz': 150, 'doesnt': 37, 'mess': 109, 'around': 5, 'ever': 48, 'saw': 151, 'nasty': 116, 'surreal': 178, 'couldnt': 25, 'ready': 142, 'watched': 199, 'developed': 32, 'taste': 179, 'got': 73, 'accustomed': 0, 'levels': 96, 'graphic': 74, 'injustice': 87, 'crooked': 26, 'guards': 77, 'wholl': 202, 'sold': 170, 'nickel': 118, 'inmates': 88, 'kill': 92, 'order': 122, 'get': 67, 'away': 7, 'well': 201, 'mannered': 102, 'middle': 112, 'class': 18, 'turned': 191, 'bitches': 10, 'lack': 94, 'street': 175, 'skills': 169, 'experience': 51, 'may': 107, 'become': 9, 'comfortable': 22, 'uncomfortable': 193, 'viewingthats': 196, 'touch': 187, 'darker': 28, 'side': 168, 'wonderful': 204, 'little': 98, 'production': 138, 'filming': 60, 'technique': 180, 'unassuming': 192, 'oldtimebbc': 120, 'fashion': 59, 'gives': 69, 'comforting': 23, 'sometimes': 172, 'discomforting': 35, 'sense': 159, 'realism': 143, 'entire': 45, 'piece': 132, 'actors': 1, 'extremely': 53, 'chosen': 15, 'michael': 111, 'sheen': 165, 'polari': 134, 'voices': 198, 'pat': 128, 'truly': 189, 'see': 158, 'seamless': 155, 'editing': 42, 'guided': 78, 'references': 145, 'williams': 203, 'diary': 33, 'entries': 46, 'worth': 207, 'terrificly': 183, 'written': 210, 'performed': 130, 'masterful': 104, 'great': 75, 'masters': 105, 'comedy': 20, 'life': 97, 'really': 144, 'comes': 21, 'things': 185, 'fantasy': 57, 'guard': 76, 'rather': 141, 'traditional': 188, 'dream': 39, 'techniques': 181, 'remains': 147, 'solid': 171, 'disappears': 34, 'plays': 133, 'knowledge': 93, 'senses': 160, 'particularly': 127, 'concerning': 24, 'orton': 123, 'halliwell': 79, 'sets': 162, 'flat': 62, 'halliwells': 80, 'murals': 114, 'decorating': 31, 'every': 49, 'surface': 177, 'terribly': 182, 'done': 38}\n"
     ]
    }
   ],
   "source": [
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00b93ca4-d255-483a-9e31-c9d0bbd6c670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 2 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0\n",
      "  1 1 0 0 1 2 0 1 1 0 0 2 1 0 1 1 1 0 1 1 1 0 1 0 0 2 0 1 3 1 1 2 1 0 1 1\n",
      "  1 1 1 0 0 1 0 0 0 1 1 1 2 1 1 1 2 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1\n",
      "  1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 5 1 0 0 1 0 1 0 0 0 1 3 1 0 1 1 0 1 0\n",
      "  0 0 1 0 1 2 1 1 2 1 1 0 1 1 0 0 0 1 0 1 1 0 3 1 1 1 1 0 0 1 1 1 2 0 1 1\n",
      "  0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 1 1 4 0 1 2 1 2 0 0 1 1 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d5820-3ceb-4953-9845-86b26a66e0a5",
   "metadata": {},
   "source": [
    "Above we can see Bag of Words in action. The above output shows the vocabulary of the dataset and the below one shows the array. We will now see ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18aa5fdb-6b07-4d68-ae4e-68fbe7b6041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ngram  = CountVectorizer(ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2437ce26-551f-4f1f-8375-aa1a3cd20f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_ng = cv_ngram.fit_transform(df.iloc[:2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70daa52d-0d0f-48fb-b859-f03d8c7b0c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one reviewers': 133, 'reviewers mentioned': 170, 'mentioned watching': 119, 'watching oz': 231, 'oz episode': 138, 'episode youll': 49, 'youll hooked': 247, 'hooked right': 95, 'right exactly': 171, 'exactly happened': 52, 'happened methe': 88, 'methe first': 121, 'first thing': 64, 'thing struck': 211, 'struck oz': 203, 'oz brutality': 137, 'brutality unflinching': 11, 'unflinching scenes': 221, 'scenes violence': 178, 'violence set': 227, 'set right': 186, 'right word': 172, 'word go': 241, 'go trust': 77, 'trust show': 217, 'show faint': 192, 'faint hearted': 58, 'hearted timid': 90, 'timid show': 213, 'show pulls': 193, 'pulls punches': 160, 'punches regards': 161, 'regards drugs': 168, 'drugs sex': 40, 'sex violence': 188, 'violence hardcore': 225, 'hardcore classic': 89, 'classic use': 20, 'use wordit': 223, 'wordit called': 242, 'called oz': 12, 'oz nickname': 141, 'nickname given': 130, 'given oswald': 74, 'oswald maximum': 136, 'maximum security': 117, 'security state': 182, 'state penitentary': 200, 'penitentary focuses': 146, 'focuses mainly': 66, 'mainly emerald': 111, 'emerald city': 45, 'city experimental': 17, 'experimental section': 54, 'section prison': 181, 'prison cells': 155, 'cells glass': 13, 'glass fronts': 76, 'fronts face': 70, 'face inwards': 56, 'inwards privacy': 99, 'privacy high': 157, 'high agenda': 91, 'agenda em': 2, 'em city': 44, 'city home': 18, 'home manyaryans': 94, 'manyaryans muslims': 114, 'muslims gangstas': 126, 'gangstas latinos': 71, 'latinos christians': 105, 'christians italians': 16, 'italians irish': 101, 'irish moreso': 100, 'moreso scuffles': 124, 'scuffles death': 179, 'death stares': 31, 'stares dodgy': 199, 'dodgy dealings': 37, 'dealings shady': 30, 'shady agreements': 189, 'agreements never': 3, 'never far': 128, 'far awayi': 60, 'awayi would': 8, 'would say': 244, 'say main': 175, 'main appeal': 110, 'appeal show': 4, 'show due': 191, 'due fact': 41, 'fact goes': 57, 'goes shows': 78, 'shows wouldnt': 194, 'wouldnt dare': 245, 'dare forget': 28, 'forget pretty': 68, 'pretty pictures': 153, 'pictures painted': 148, 'painted mainstream': 142, 'mainstream audiences': 112, 'audiences forget': 6, 'forget charm': 67, 'charm forget': 14, 'forget romanceoz': 69, 'romanceoz doesnt': 173, 'doesnt mess': 38, 'mess around': 120, 'around first': 5, 'first episode': 63, 'episode ever': 48, 'ever saw': 50, 'saw struck': 174, 'struck nasty': 202, 'nasty surreal': 127, 'surreal couldnt': 205, 'couldnt say': 26, 'say ready': 176, 'ready watched': 163, 'watched developed': 230, 'developed taste': 33, 'taste oz': 206, 'oz got': 139, 'got accustomed': 79, 'accustomed high': 0, 'high levels': 92, 'levels graphic': 106, 'graphic violence': 81, 'violence violence': 228, 'violence injustice': 226, 'injustice crooked': 96, 'crooked guards': 27, 'guards wholl': 84, 'wholl sold': 238, 'sold nickel': 196, 'nickel inmates': 129, 'inmates wholl': 98, 'wholl kill': 237, 'kill order': 102, 'order get': 134, 'get away': 72, 'away well': 7, 'well mannered': 235, 'mannered middle': 113, 'middle class': 123, 'class inmates': 19, 'inmates turned': 97, 'turned prison': 218, 'prison bitches': 154, 'bitches due': 10, 'due lack': 42, 'lack street': 104, 'street skills': 201, 'skills prison': 195, 'prison experience': 156, 'experience watching': 53, 'oz may': 140, 'may become': 118, 'become comfortable': 9, 'comfortable uncomfortable': 23, 'uncomfortable viewingthats': 220, 'viewingthats get': 224, 'get touch': 73, 'touch darker': 214, 'darker side': 29, 'wonderful little': 240, 'little production': 108, 'production filming': 158, 'filming technique': 62, 'technique unassuming': 207, 'unassuming oldtimebbc': 219, 'oldtimebbc fashion': 131, 'fashion gives': 61, 'gives comforting': 75, 'comforting sometimes': 24, 'sometimes discomforting': 198, 'discomforting sense': 36, 'sense realism': 184, 'realism entire': 164, 'entire piece': 46, 'piece actors': 149, 'actors extremely': 1, 'extremely well': 55, 'well chosen': 233, 'chosen michael': 15, 'michael sheen': 122, 'sheen got': 190, 'got polari': 80, 'polari voices': 152, 'voices pat': 229, 'pat truly': 145, 'truly see': 216, 'see seamless': 183, 'seamless editing': 180, 'editing guided': 43, 'guided references': 85, 'references williams': 167, 'williams diary': 239, 'diary entries': 34, 'entries well': 47, 'well worth': 236, 'worth watching': 243, 'watching terrificly': 232, 'terrificly written': 210, 'written performed': 246, 'performed piece': 147, 'piece masterful': 150, 'masterful production': 115, 'production one': 159, 'one great': 132, 'great masters': 82, 'masters comedy': 116, 'comedy life': 21, 'life realism': 107, 'realism really': 165, 'really comes': 166, 'comes home': 22, 'home little': 93, 'little things': 109, 'things fantasy': 212, 'fantasy guard': 59, 'guard rather': 83, 'rather use': 162, 'use traditional': 222, 'traditional dream': 215, 'dream techniques': 39, 'techniques remains': 208, 'remains solid': 169, 'solid disappears': 197, 'disappears plays': 35, 'plays knowledge': 151, 'knowledge senses': 103, 'senses particularly': 185, 'particularly scenes': 144, 'scenes concerning': 177, 'concerning orton': 25, 'orton halliwell': 135, 'halliwell sets': 86, 'sets particularly': 187, 'particularly flat': 143, 'flat halliwells': 65, 'halliwells murals': 87, 'murals decorating': 125, 'decorating every': 32, 'every surface': 51, 'surface terribly': 204, 'terribly well': 209, 'well done': 234}\n"
     ]
    }
   ],
   "source": [
    "print(cv_ngram.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d757c47-dc78-499e-ae8b-3ce45ca46da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0\n",
      "  0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 1 1 1\n",
      "  1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0\n",
      "  0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 0\n",
      "  0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1\n",
      "  0 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0\n",
      "  0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 2 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_ng[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc54fe-74d3-4e52-a6bd-9c4212d22a58",
   "metadata": {},
   "source": [
    "The above was a representation of bi-gram but we can make n-gram by providing the hyperparameter. This still has many problems so we will now see Tf-Idf. Here we calculate Term frequency and Inverse document frequency to value words which are rare to a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ba17ef8-c122-4156-8abc-354ec0a7483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a1b1a10-4906-437b-ab5d-742aec989285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06508585, 0.        , 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.        , 0.06508585, 0.13017169, 0.06508585, 0.06508585,\n",
       "        0.        , 0.        , 0.06508585, 0.        , 0.        ,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.        , 0.06508585, 0.        , 0.        ,\n",
       "        0.        , 0.06508585, 0.06508585, 0.        , 0.        ,\n",
       "        0.06508585, 0.13017169, 0.        , 0.06508585, 0.06508585,\n",
       "        0.        , 0.        , 0.13017169, 0.06508585, 0.        ,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.        , 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.        , 0.06508585, 0.        ,\n",
       "        0.        , 0.13017169, 0.        , 0.06508585, 0.19525754,\n",
       "        0.06508585, 0.06508585, 0.13017169, 0.06508585, 0.        ,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.04630912, 0.06508585,\n",
       "        0.        , 0.        , 0.06508585, 0.        , 0.        ,\n",
       "        0.        , 0.06508585, 0.06508585, 0.06508585, 0.13017169,\n",
       "        0.04630912, 0.06508585, 0.06508585, 0.13017169, 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.        , 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.        , 0.        , 0.06508585,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.06508585, 0.        ,\n",
       "        0.        , 0.06508585, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.        , 0.06508585, 0.06508585, 0.        ,\n",
       "        0.06508585, 0.06508585, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.        , 0.04630912, 0.06508585, 0.        , 0.06508585,\n",
       "        0.32542923, 0.06508585, 0.        , 0.        , 0.06508585,\n",
       "        0.        , 0.06508585, 0.        , 0.        , 0.        ,\n",
       "        0.06508585, 0.19525754, 0.06508585, 0.        , 0.06508585,\n",
       "        0.06508585, 0.        , 0.06508585, 0.        , 0.        ,\n",
       "        0.        , 0.06508585, 0.        , 0.06508585, 0.13017169,\n",
       "        0.06508585, 0.06508585, 0.13017169, 0.04630912, 0.06508585,\n",
       "        0.        , 0.06508585, 0.06508585, 0.        , 0.        ,\n",
       "        0.        , 0.06508585, 0.        , 0.06508585, 0.06508585,\n",
       "        0.        , 0.19525754, 0.06508585, 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.        , 0.        , 0.06508585, 0.06508585,\n",
       "        0.06508585, 0.13017169, 0.        , 0.06508585, 0.06508585,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06508585,\n",
       "        0.        , 0.06508585, 0.06508585, 0.        , 0.        ,\n",
       "        0.06508585, 0.06508585, 0.        , 0.06508585, 0.06508585,\n",
       "        0.04630912, 0.06508585, 0.26034338, 0.        , 0.06508585,\n",
       "        0.09261823, 0.04630912, 0.13017169, 0.        , 0.        ,\n",
       "        0.06508585, 0.06508585, 0.        , 0.06508585, 0.06508585,\n",
       "        0.        , 0.06508585],\n",
       "       [0.        , 0.10392245, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10392245, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10392245, 0.10392245, 0.        , 0.10392245, 0.10392245,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10392245, 0.        , 0.10392245, 0.10392245,\n",
       "        0.10392245, 0.        , 0.        , 0.10392245, 0.10392245,\n",
       "        0.        , 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.10392245, 0.10392245, 0.        , 0.        , 0.10392245,\n",
       "        0.        , 0.        , 0.        , 0.10392245, 0.        ,\n",
       "        0.        , 0.        , 0.10392245, 0.        , 0.10392245,\n",
       "        0.10392245, 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10392245,\n",
       "        0.        , 0.        , 0.        , 0.07394168, 0.        ,\n",
       "        0.10392245, 0.10392245, 0.        , 0.10392245, 0.10392245,\n",
       "        0.10392245, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07394168, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10392245, 0.        ,\n",
       "        0.        , 0.        , 0.10392245, 0.2078449 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10392245,\n",
       "        0.10392245, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10392245, 0.        , 0.        , 0.10392245,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10392245, 0.07394168, 0.        , 0.10392245, 0.        ,\n",
       "        0.        , 0.        , 0.2078449 , 0.10392245, 0.        ,\n",
       "        0.10392245, 0.        , 0.2078449 , 0.10392245, 0.10392245,\n",
       "        0.        , 0.        , 0.        , 0.2078449 , 0.        ,\n",
       "        0.        , 0.10392245, 0.        , 0.2078449 , 0.10392245,\n",
       "        0.10392245, 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07394168, 0.        ,\n",
       "        0.10392245, 0.        , 0.        , 0.10392245, 0.10392245,\n",
       "        0.10392245, 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.10392245, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10392245, 0.10392245, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.10392245, 0.10392245, 0.10392245, 0.10392245, 0.        ,\n",
       "        0.10392245, 0.        , 0.        , 0.10392245, 0.10392245,\n",
       "        0.        , 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.07394168, 0.        , 0.        , 0.10392245, 0.        ,\n",
       "        0.07394168, 0.22182504, 0.        , 0.10392245, 0.10392245,\n",
       "        0.        , 0.        , 0.10392245, 0.        , 0.        ,\n",
       "        0.10392245, 0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(df.iloc[0: 2, 0]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51b82f-24e1-4716-a99f-321efc086983",
   "metadata": {},
   "source": [
    "The above represents the tfidf array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73955cfc-a444-4993-9bc5-7f1f19724cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.         1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.         1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.         1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.         1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.         1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.         1.         1.40546511 1.40546511\n",
      " 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511 1.40546511\n",
      " 1.40546511 1.40546511]\n",
      "['accustomed' 'actors' 'agenda' 'agreements' 'appeal' 'around' 'audiences'\n",
      " 'away' 'awayi' 'become' 'bitches' 'brutality' 'called' 'cells' 'charm'\n",
      " 'chosen' 'christians' 'city' 'class' 'classic' 'comedy' 'comes'\n",
      " 'comfortable' 'comforting' 'concerning' 'couldnt' 'crooked' 'dare'\n",
      " 'darker' 'dealings' 'death' 'decorating' 'developed' 'diary' 'disappears'\n",
      " 'discomforting' 'dodgy' 'doesnt' 'done' 'dream' 'drugs' 'due' 'editing'\n",
      " 'em' 'emerald' 'entire' 'entries' 'episode' 'ever' 'every' 'exactly'\n",
      " 'experience' 'experimental' 'extremely' 'face' 'fact' 'faint' 'fantasy'\n",
      " 'far' 'fashion' 'filming' 'first' 'flat' 'focuses' 'forget' 'fronts'\n",
      " 'gangstas' 'get' 'given' 'gives' 'glass' 'go' 'goes' 'got' 'graphic'\n",
      " 'great' 'guard' 'guards' 'guided' 'halliwell' 'halliwells' 'happened'\n",
      " 'hardcore' 'hearted' 'high' 'home' 'hooked' 'injustice' 'inmates'\n",
      " 'inwards' 'irish' 'italians' 'kill' 'knowledge' 'lack' 'latinos' 'levels'\n",
      " 'life' 'little' 'main' 'mainly' 'mainstream' 'mannered' 'manyaryans'\n",
      " 'masterful' 'masters' 'maximum' 'may' 'mentioned' 'mess' 'methe'\n",
      " 'michael' 'middle' 'moreso' 'murals' 'muslims' 'nasty' 'never' 'nickel'\n",
      " 'nickname' 'oldtimebbc' 'one' 'order' 'orton' 'oswald' 'oz' 'painted'\n",
      " 'particularly' 'pat' 'penitentary' 'performed' 'pictures' 'piece' 'plays'\n",
      " 'polari' 'pretty' 'prison' 'privacy' 'production' 'pulls' 'punches'\n",
      " 'rather' 'ready' 'realism' 'really' 'references' 'regards' 'remains'\n",
      " 'reviewers' 'right' 'romanceoz' 'saw' 'say' 'scenes' 'scuffles'\n",
      " 'seamless' 'section' 'security' 'see' 'sense' 'senses' 'set' 'sets' 'sex'\n",
      " 'shady' 'sheen' 'show' 'shows' 'side' 'skills' 'sold' 'solid' 'sometimes'\n",
      " 'stares' 'state' 'street' 'struck' 'surface' 'surreal' 'taste'\n",
      " 'technique' 'techniques' 'terribly' 'terrificly' 'thing' 'things' 'timid'\n",
      " 'touch' 'traditional' 'truly' 'trust' 'turned' 'unassuming'\n",
      " 'uncomfortable' 'unflinching' 'use' 'viewingthats' 'violence' 'voices'\n",
      " 'watched' 'watching' 'well' 'wholl' 'williams' 'wonderful' 'word'\n",
      " 'wordit' 'worth' 'would' 'wouldnt' 'written' 'youll']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1250059-ce4e-4db7-8376-3ffaa51ec187",
   "metadata": {},
   "source": [
    "The above is the idf and the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f8b33-eb33-4455-a880-73155fbcf69e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
